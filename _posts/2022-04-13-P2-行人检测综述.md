---
layout: post
title: 2022-04-13-P2-行人检测综述 
tags: [cv]
category: ReID
toc: true
math: true
author: zzhc
---


## 1. 行人检测常用方法

***

### 1.1 基于运动检测的方法

#### 1.1.1 思路 
&emsp;&emsp;前面的帧学习得到背景模型，当前帧与背景帧比较，得到运动的目标。

#### 1.1.2 问题

- 只能检测运动的目标，静止的目标无法处理；
- 受光照变化、阴影的影响很大；
- 容易受到恶劣天气如雨雪，以及树叶晃动等干扰物的影响；
- 如果目标的颜色和背景很接近，会造成漏检和断裂；
- 如果多个目标粘连，重叠，则无法处理。

#### 1.1.3 原因
&emsp;&emsp;只利用了像素级的信息，没有利用图像更高层语义信息。

<br>

***

### 1.2 基于传统机器学习的方法

#### 思路
&emsp;&emsp;特征提取+分类器

#### 特征提取
- a) 底层特征
    - 优点：单一特征，计算速度快
    - 缺点：只从某一方面描述行人特征，判别力较差

- b) 基于学习的特征
    - 优点：能从大量的样本中选择去判别能力较强的特征
    - 缺点：特征的选择质量与训练样本密切相关，若训练集代表性差则很难选出好的特征

- c) 混合特征
    - 优点：从不同方向描述图像特征
    - 缺点：特征维度增加，训练与预测的时间长，部分终端设备无法满足其算力要求












<br>

***

### 1.3 基于深度学习的方法

 - **SSD：**全称Single Shot MultiBox Detector，是Wei Liu在ECCV 2016上提出的一种目标检测算法，截至目前是主要的检测框架之一。
 - **FPN：**特征金字塔网络(Feature Pyramid Network)简称FPN，是一种自顶向下的特征融合方法，但是FPN是一种多尺度的目标检测算法，即不只有一个特征预测层。
 - **YOLO：**“You Only Look Once”或“YOLO”是一个对象检测算法的名字，这是Redmon等人在2016年的一篇研究论文中命名的。YOLO实现了自动驾驶汽车等前沿技术中使用的实时对象检测。OLO将对象检测重新定义为一个回归问题。它将单个卷积神经网络(CNN)应用于整个图像，将图像分成网格，并预测每个网格的类概率和边界框。例如，以一个100x100的图像为例。我们把它分成网格，比如7x7。
 - **Cascade CNN：**级联的卷积网络，借鉴AdaBoost分类器级联的思想。前面的卷积网络简单，可以快速排除掉大部分背景区域；后面的卷积网络更复杂，用于精确的判断一个候选窗口是否为行人。
 - **JointDeep：**用HOG+CSS+SVM作为第一级检测器，进行预过滤，把它的检测结果再使用卷积神经网络来进一步判断。卷积网络输入不是RGB通道的图像，而是作者实验给出的三个通道。并采用部件检测的策略。由于遮挡的存在，作者同时设计了几种遮挡的模式。
 - **SA-FastRCNN：**针对行人检测的特点对Fast R-CNN进行了改进，由于大尺寸和小尺寸行人提取的特征显示出显着差异，作者分别针对大尺寸和小尺寸行人设计了2个子网络分别进行检测。利用训练阶段得到的scale-aware权值将一个大尺度子网络和小尺度子网络合并到统一的框架中，利用候选区域高度估计这两个子网络的scale-aware权值。
 - **RepLoss：**由旷视科技提出。主要目标是解决遮挡问题，为此设计了一种称为RepLoss的损失函数。
 - **HyperLearner：**改进自Faster R-CNN。使用了一些额外的特征来解决“行人与背景的区分度低”的问题。











<br>
<br>

***


## 2. 常用数据集

- **MIT行人数据集：**
较早公开的行人数据集。包含正面和背面两个视角的彩色行人图像，数据库未划分训练集和测试集，且不包含负样本。目前较少使用INRIA行人数据集
目前使用较多的静态行人数据集，包含训练集和测试集，且均包含正样本和负样本。该库行人所处背景复杂，人的姿态也较多，而且含有光照等环境因素的变化，更加符合实际场景。











- **Daimer行人数据集：**
图像来源与车载摄像机，分为检测数据集与分类数据集，图片均是灰度图片。每个子数据集均由训练集和测试集组成。测试集是一段大约27分钟的视频，视频中包含完整的以及被部分遮挡的行人。数据库中还包含三个只有负样本的子数据库。但因为该库大量正样本由较少的正样本经过移位或镜像生成，所以重要特征会出现在相邻位置产生模糊效应，导致预测效果不佳。







- **Caltech行人数据集：**
图像来源与车载摄像机，与现实中图像的实际遮挡率一致，其中包含一些质量不好的图像。数据集分为训练集和测试集，但测试集的标注信息尚未公开。


- **TUD行人数据集：**
该数据集主要用于评估运动信息在行人检测中的作用，常用于行人检测及追踪中。


- **NICTA行人数据集：**
规模较大的静态图像行人数据库，包含25551张单人图像和5207张高分辨率非行人图像，已划分好训练集与测试集。


- **ETH行人数据集：**
基于双目视觉的行人数据集，采用一对车载摄像头拍摄获得。给出了标定信息和行人标注信息。该数据库主要用于多个行人的检测与跟踪研究。



- **CVC行人数据集：**
目前包含三个数据集：CVC-01，CVC-02和CVC-Virtual。该数据库主要用于车辆辅助驾驶中的行人检测研究。



- **USC行人数据集：**
大部分来自于监控视频，是一个比较小的行人数据库，包含3组数据集：USC-A，USC-B和USC-C。USC-A中包含正面或者背面拍摄的行人，行人之间无相互遮挡；USC-B中包含多个视角下且存在相互遮挡的行人；USC-C包含多视角下无相互遮挡的行人。该数据库主要用于存在遮挡和多视角情况下的行人检测研究。




<br>
<br>

***


## 3. 参考文献

[1] 祁磊, 等. 弱监督场景下的行人重识别研究综述
[2] 苏松志, 李绍滋, 陈淑媛等. 行人检测技术综述[J]. 电子学报, 2012, 40(004):814-820.
[3] 蔡小路. 基于分类器算法的行人检测研究[D]. 成都: 电子科技大学, 2015.
[4] 张春凤, 宋加涛, 王万良. 行人检测技术研究综述[J]. 电视技术, 2014, 38(3).
[4] W. Ouyang, X. Wang, Joint Deep Learning for Pedestrian Detection[J]. CVPR, 2013: 2056-2063.
[5] Li J, Liang X, Shen S M, 等. Scale-aware Fast R-CNN for Pedestrian Detection[J]. IEEE Transactions on Multimedia, 2015: 1-1.
[6] Zhang L, Lin L , Liang X, 等. Is Faster R-CNN Doing Well for Pedestrian Detection?[J]. ECCV, 2016: 443-457.
[7] Wang X, Xiao T, Jiang Y, 等. Repulsion Loss: Detecting Pedestrians in a Crowd[J]. CVPR, 2017: 7774-7783.
[8] Mao J, Xiao T, Jiang Y, 等. What Can Help Pedestrian Detection?[C]. CVPR: IEEE, 2017.



