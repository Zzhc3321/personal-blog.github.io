---
layout: post
title: 2022-05-28-网络结构_Alexnet 
tags: [深度学习]
category: 深度学习
toc: true
math: true
author: zzhc
---

&emsp;&emsp;该神经网络有6000万个参数和65万个神经元，由五个卷积层组成，其中一些卷积层后面是最大池层，三个完全连接的层最后是1000-way的softmax。为了减少完全连接层中的过度拟合，我们采用了“dropout”的正则化方法。

<br>
<br>

***

## Introduction

### 研究背景和重要性（Background And Importance）

&emsp;&emsp;当前的目标识别主要使用机器学习方法。为了提高性能，收集更大的数据集以学习更强大的模型，并使用更好的技术来防止过度拟合。

&emsp;&emsp;小型图像数据集的缺点已是共识，但直到最近才有可能收集具有数百万图像的标记数据集。LabelMe,ImageNet...

&emsp;&emsp;与具有相似大小层的标准前馈神经网络相比，CNN具有更少的连接和参数，因此更易于训练，而其理论上的最佳性能可能只会稍差。 

&emsp;&emsp;尽管CNN具有相对高效的架构，但在大规模应用于高分辨率图像时，其成本仍然很高高。不过当前的GPU和高度优化的二维卷积实现，使训练CNN成为可能并且不会出现严重的过拟合。



### 引出该领域科研空白（What Is Unknown）

无

### 点题—指出本文的研究课题（Topic Of Research Paper）


### 概述文章的核心方法论和主要发现（Highlight The Approach And Principal Findings）
&emsp;&emsp;本文的具体贡献如下：我们在ILSVRC-2010和ILSVRC-2012竞赛中使用的ImageNet子集上训练了迄今为止最大的卷积神经网络之一[2]，并取得了迄今为止在这些数据集上报告的最佳结果。

### 提出猜想和研究目的（Hypothesis And Objectives）
&emsp;&emsp;网络在两个GTX 580 3GB GPU上进行训练需要五到六天的时间。实验都表明，只要等待更快的GPU和更大的数据集可用，结果就可以得到改善。 


<br>
<br>

***

## The Dataset

&emsp;&emsp;ImageNet是一个包含超过1500万张高分辨率标记图像的数据集，这些图像属于大约22000个类别。



<br>
<br>

***

## The Architecture
&emsp;&emsp;网络包含八层，其中五个卷积层和三个完全连接层。最后一个完全连接的层的输出被馈送到1000-way的softmax，该softmax在1000个类别标签上产生分布。

![enter description here](http://img.zzhc321.xyz/blog/1653707190487.png)

 1. 第一个卷积层使用96个大小为11×11×3、步长为4像素的核，对224×224×3的输入图像进行过滤；
 2. 第二个卷积层将第一层的（归一化 池化）输出作为输入，并使用大小为5×5×48的256个核对其进行过滤；
 3. 第三个卷积层有384个大小为3×3×256的内核，这些内核连接到第二个卷积层的（归一化、池化）输出。
 4. 第四卷积层有384个大小为3×3×192的核；
 5. 第五卷积层有256个大小为3×3×192的核；
 6. 完全连接的层各有4096个神经元；





<br>
<br>

***

## Reducing Overfitting

### Data Augmentation
&emsp;&emsp;The easiest and most common method to reduce overfitting on image data is to artificially enlarge
the dataset using label-preserving transformations

### Dropout

&emsp;&emsp;将每个隐藏神经元的输出以概率为0.5设置为零。以这种方式“Dropout”的神经元不参与正向传递，也不参与反向传播。




<br>
<br>

***

## Details of learning



<br>
<br>

***

## Results


<br>
<br>

***

## Discussion


&emsp;&emsp;需要注意的是，如果删除单个卷积层，我们的网络性能会下降。例如，删除任何中间层都会导致网络顶级性能损失约2%。因此，深度对于实现我们的成果非常重要。 